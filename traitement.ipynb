{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_directory_contents(dir_path):\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        level = root.replace(dir_path, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 4 * (level + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw-data/\n",
      "    AbstractScenes_v1.1/\n",
      "        AbstractScenes_v1.1/\n",
      "            Pngs/\n",
      "            RenderedScenes/\n",
      "            RenderedSeedScenes/\n",
      "            SemanticClassesRender/\n",
      "            SimpleSentences/\n",
      "                tuples/\n",
      "            VisualFeatures/\n",
      "            WordFeatures/\n",
      "    CoDraw/\n",
      "        asset/\n",
      "        css/\n",
      "        dataset/\n",
      "        images/\n",
      "        imgs/\n",
      "        js/\n",
      "        output/\n",
      "        script/\n",
      "            .mypy_cache/\n",
      "                3.6/\n",
      "                    collections/\n",
      "                    json/\n",
      "                    os/\n",
      "    GloVe/\n",
      "    i-CLEVR/\n",
      "        images/\n",
      "            .ipynb_checkpoints/\n",
      "        scenes/\n",
      "            .ipynb_checkpoints/\n",
      "        text/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory_path = 'raw-data'\n",
    "list_directory_contents(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import random\n",
    "\n",
    "def augment_images_in_folder(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.png'):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            with Image.open(img_path) as img:\n",
    "                # Apply random rotation\n",
    "                if random.choice([True, False]):\n",
    "                    img = img.rotate(random.randint(-30, 30), expand=True)\n",
    "                \n",
    "                # Apply random scaling\n",
    "                if random.choice([True, False]):\n",
    "                    scale = random.uniform(0.8, 1.2)  # Scale between 80% and 120%\n",
    "                    width, height = img.size\n",
    "                    img = img.resize((int(width * scale), int(height * scale)))\n",
    "                \n",
    "                # Apply random translation\n",
    "                if random.choice([True, False]):\n",
    "                    img = ImageOps.exif_transpose(img)\n",
    "                \n",
    "                # Apply random flipping\n",
    "                if random.choice([True, False]):\n",
    "                    img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                \n",
    "                # Save the augmented image\n",
    "                img.save(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "augment_images_in_folder('raw-data/AbstractScenes_v1.1/AbstractScenes_v1.1/Pngs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "def random_noise(image):\n",
    "    # Convert image to array\n",
    "    img_array = np.array(image)\n",
    "    # Generate noise and add it to the image\n",
    "    noise = np.random.randint(-30, 30, img_array.shape, dtype='int16')\n",
    "    img_array = img_array + noise\n",
    "    img_array = np.clip(img_array, 0, 255)  # Ensure pixel values are valid\n",
    "    return Image.fromarray(img_array.astype('uint8'))\n",
    "\n",
    "def adjust_colors(image):\n",
    "    # Randomly adjust the brightness, contrast, and color\n",
    "    enhancers = [\n",
    "        ImageEnhance.Brightness(image),\n",
    "        ImageEnhance.Contrast(image),\n",
    "        ImageEnhance.Color(image)\n",
    "    ]\n",
    "    factors = [random.uniform(0.5, 1.5) for _ in enhancers]  # Random factor between 0.5 and 1.5\n",
    "    \n",
    "    for enhancer, factor in zip(enhancers, factors):\n",
    "        image = enhancer.enhance(factor)\n",
    "    return image\n",
    "\n",
    "def augment_images_in_folder(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.png'):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            with Image.open(img_path) as img:\n",
    "                # Apply random noise\n",
    "                if random.choice([True, False]):\n",
    "                    img = random_noise(img)\n",
    "                \n",
    "                # Apply random color adjustments\n",
    "                if random.choice([True, False]):\n",
    "                    img = adjust_colors(img)\n",
    "\n",
    "                # Save the augmented image\n",
    "                img.save(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "augment_images_in_folder('raw-data/CoDraw/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "def apply_noise(image):\n",
    "    img_array = np.asarray(image).astype(np.int16)\n",
    "    noise = np.random.randint(-20, 20, img_array.shape)\n",
    "    noisy_img = img_array + noise\n",
    "    noisy_img = np.clip(noisy_img, 0, 255)  #\n",
    "    return Image.fromarray(noisy_img.astype('uint8'))\n",
    "\n",
    "def apply_blur(image):\n",
    "    return image.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.5, 2.0)))\n",
    "\n",
    "def apply_sharpen(image):\n",
    "    return image.filter(ImageFilter.UnsharpMask(radius=1, percent=150))\n",
    "\n",
    "def augment_images_in_folder(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.png'):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            with Image.open(img_path) as img:\n",
    "                actions = [apply_noise, apply_blur, apply_sharpen]\n",
    "                random.shuffle(actions)  \n",
    "                for action in actions:\n",
    "                    if random.choice([True, False]):  \n",
    "                        img = action(img)\n",
    "                img.save(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_images_in_folder('raw-data/i-CLEVR/images')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textual data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Rania\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Rania\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Rania\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Rania\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rania\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rania\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "avoid_verbs = {\"is\", \"am\", \"are\", \"was\", \"were\", \"be\", \"being\", \"been\", \"have\", \"has\", \"had\"}\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "    return tag_dict.get(tag[0].upper(), wordnet.NOUN)\n",
    "\n",
    "def most_similar_synonym(word, pos):\n",
    "    if word in stop_words or word in avoid_verbs:\n",
    "        return word  # Skip stopwords and specific verbs\n",
    "    synsets = wordnet.synsets(word, pos=pos)\n",
    "    if not synsets:\n",
    "        return word\n",
    "    best_synonym = word\n",
    "    best_similarity = 0.0\n",
    "    original_synset = synsets[0]  # Assuming the first synset is the most common usage\n",
    "    for synset in synsets:\n",
    "        for lemma in synset.lemmas():\n",
    "            if lemma.name() == word:\n",
    "                continue\n",
    "            similarity = original_synset.path_similarity(synset)\n",
    "            if similarity and similarity > 0.9 and similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_synonym = lemma.name().replace('_', ' ')\n",
    "    return best_synonym if best_similarity > 0.9 else word\n",
    "\n",
    "def synonym_replacement(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    tagged_words = pos_tag(words)\n",
    "    new_words = words.copy()\n",
    "    for i, (word, tag) in enumerate(tagged_words):\n",
    "        if tag.startswith('NNP') or word.lower() in stop_words or word.lower() in avoid_verbs:  # Skip proper nouns and specific words\n",
    "            continue\n",
    "        wn_tag = get_wordnet_pos(tag)\n",
    "        new_words[i] = most_similar_synonym(word, wn_tag)\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "def process_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        sentences = file.readlines()\n",
    "    \n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        for sentence in sentences:\n",
    "            modified_sentence = synonym_replacement(sentence.strip())\n",
    "            file.write(modified_sentence + '\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'raw-data/AbstractScenes_v1.1/AbstractScenes_v1.1/Sentences_1002.txt'\n",
    "process_file(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the word embedding model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load the binary Word2Vec model\n",
    "model = KeyedVectors.load_word2vec_format('raw-data/GloVe/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Save the model in text format\n",
    "model.save_word2vec_format('raw-data/GloVe/GoogleNews-vectors-negative300.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
